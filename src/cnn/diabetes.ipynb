{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OcPfQPx7hET",
        "outputId": "3dd6a161-5bf3-496b-80c8-845413fe786e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.utils._bunch.Bunch'>\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "diabetes = load_diabetes()  # データセットの読み込み\n",
        "\n",
        "#print(diabetes.DESCR)\n",
        "\n",
        "print(type(diabetes))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)  # データフレーム型に格納、特徴量の名前を列に加える\n",
        "print(df.head())\n",
        "\n",
        "df['Progression'] = diabetes.target  # ターゲットデータ（教師データ）もデータフレームに格納\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J_kVVPe7llW",
        "outputId": "b6f5d70a-0b5a-4e92-a2dd-dfe0c79c5ab5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        age       sex       bmi        bp        s1        s2        s3  \\\n",
            "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
            "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
            "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
            "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
            "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
            "\n",
            "         s4        s5        s6  \n",
            "0 -0.002592  0.019907 -0.017646  \n",
            "1 -0.039493 -0.068332 -0.092204  \n",
            "2 -0.002592  0.002861 -0.025930  \n",
            "3  0.034309  0.022688 -0.009362  \n",
            "4 -0.002592 -0.031988 -0.046641  \n",
            "        age       sex       bmi        bp        s1        s2        s3  \\\n",
            "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
            "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
            "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
            "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
            "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
            "\n",
            "         s4        s5        s6  Progression  \n",
            "0 -0.002592  0.019907 -0.017646        151.0  \n",
            "1 -0.039493 -0.068332 -0.092204         75.0  \n",
            "2 -0.002592  0.002861 -0.025930        141.0  \n",
            "3  0.034309  0.022688 -0.009362        206.0  \n",
            "4 -0.002592 -0.031988 -0.046641        135.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "data = diabetes.data\n",
        "label = diabetes.target\n",
        "\n",
        "print(type(data))  # ndarray型\n",
        "print(type(label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy9mrPRY74NY",
        "outputId": "419defd7-bdd4-428d-97d9-da06e06fcdc5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data, train_label, test_label = train_test_split(  # trainデータとtestデータに分割\n",
        "    data, label, test_size=0.2)\n",
        "print(\"train_data size: {}\".format(len(train_data)))\n",
        "print(\"test_data size: {}\".format(len(test_data)))\n",
        "print(\"train_label size: {}\".format(len(train_label)))\n",
        "print(\"test_label size: {}\".format(len(test_label)))\n",
        "\n",
        "print(type(train_data))  # 型は変わらない"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hrRlmWu760r",
        "outputId": "3ebd5cb5-2180-4e63-f288-da7aaf09c3d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data size: 353\n",
            "test_data size: 89\n",
            "train_label size: 353\n",
            "test_label size: 89\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 型をテンソルに変える\n",
        "train_x = torch.Tensor(train_data)\n",
        "test_x = torch.Tensor(test_data)\n",
        "train_y = torch.Tensor(train_label)\n",
        "test_y = torch.Tensor(test_label)\n",
        "print(type(train_x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-xuuyjU78iW",
        "outputId": "136da080-790d-4e2e-fc41-bb03d620b7cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# データをテンソルのデータにセットする. 引数として 入力データ, 教師データ とすれば良い\n",
        "train_dataset = TensorDataset(train_x, train_y)\n",
        "test_dataset = TensorDataset(test_x, test_y)\n",
        "print(type(train_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L42aZIH7-N3",
        "outputId": "4b561a23-49ba-47ef-bad8-f2512c33f00b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.utils.data.dataset.TensorDataset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# データローダーの際の細かい設定をする\n",
        "train_batch = DataLoader(\n",
        "    dataset=train_dataset,  # データセットの指定\n",
        "    batch_size=5,  # バッチサイズの指定\n",
        "    shuffle=True,  # シャッフルするかどうかの指定\n",
        "    num_workers=2  # コア数\n",
        ")\n",
        "test_batch = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=5,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "## for文で回してサイズを確認する\n",
        "for data, label in train_batch:\n",
        "    print(\"batch data size: {}\".format(data.size()))  # バッチサイズが5, 特徴量（軸）が10つと分かる\n",
        "    print(\"batch label size: {}\".format(label.size()))  # バッチサイズはもちろん上と同じ5, 回帰値が入っている\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaZNto6_8DXI",
        "outputId": "daa6a7fe-87b4-40fd-939c-968817329108"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch data size: torch.Size([5, 10])\n",
            "batch label size: torch.Size([5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ニューラルネットワークを作成\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, D_in, H, D_out):  # モデルの定義. 重み, バイアスの初期化やその際のシード値固定もいずれしよう！\n",
        "        super(Net, self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(D_in, H)\n",
        "        self.linear2 = torch.nn.Linear(H, D_out)\n",
        "\n",
        "    def forward(self, x):  # 順伝播の際の動きをプログラムする\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "4M5VJWJU8ECp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## パラメータ表示\n",
        "# ハイパーパラメータ\n",
        "D_in = 10  # 入力次元（diabetesデータは10次元）\n",
        "H = 100  # 隠れ層次元\n",
        "D_out = 1  # 出力次元（回帰問題なので1次元）\n",
        "epoch = 100  # 学習回数\n",
        "## デバイスの指定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "## ネットワーク実行\n",
        "net = Net(D_in, H, D_out).to(device)\n",
        "print(\"Device: {}\".format(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmMSiSYt8Gb0",
        "outputId": "ff42b1db-4ec1-4c42-d1fe-5ddfb0bf0a51"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用する損失関数の定義（回帰なのでMSE: Mean Squared Error）\n",
        "criterion = nn.MSELoss()\n",
        "# 使用する最適化関数の定義\n",
        "optimizer = optim.Adam(net.parameters())"
      ],
      "metadata": {
        "id": "weoFRwPv8IGE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 学習に必要な空リストを作成\n",
        "train_loss_list = []  # 学習損失\n",
        "test_loss_list = []  # 評価損失\n",
        "\n",
        "# 学習の実行\n",
        "for I in range(epoch):\n",
        "    # 学習の進行状況を表示\n",
        "    print('--------')\n",
        "    print(\"Epoch: {}/{}\".format(I + 1, epoch))\n",
        "    # 損失の初期化\n",
        "    train_loss = 0  # 学習損失\n",
        "    test_loss = 0  # 評価損失\n",
        "    # 学習モードに設定\n",
        "    net.train()\n",
        "    # ミニバッチごとにデータをロードして学習\n",
        "    for data, label in train_batch:\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "        # 勾配を初期化\n",
        "        optimizer.zero_grad()\n",
        "        # データを入力して予測値を計算\n",
        "        y_pred = net(data)\n",
        "        # 損失を計算\n",
        "        loss = criterion(y_pred.squeeze(), label)\n",
        "        # 勾配を計算\n",
        "        loss.backward()\n",
        "        # パラメータの更新\n",
        "        optimizer.step()\n",
        "        # ミニバッチごとの損失を蓄積\n",
        "        train_loss += loss.item()\n",
        "    # ミニバッチの平均の損失を計算\n",
        "    batch_train_loss = train_loss / len(train_batch)\n",
        "\n",
        "    # 評価モードに設定\n",
        "    net.eval()\n",
        "    # 評価時に自動微分をゼロにする\n",
        "    with torch.no_grad():\n",
        "        for data, label in test_batch:\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "            # データを入力して予測値を計算\n",
        "            y_pred = net(data)\n",
        "            # 損失を計算\n",
        "            loss = criterion(y_pred.squeeze(), label)\n",
        "            # ミニバッチごとの損失を備蓄\n",
        "            test_loss += loss.item()\n",
        "    # ミニバッチの平均の損失を計算\n",
        "    batch_test_loss = test_loss / len(test_batch)\n",
        "\n",
        "    # エポックごとに損失を表示\n",
        "    print(\"Train_Loss: {:.4f}\".format(batch_train_loss))\n",
        "    print(\"Test_Loss: {:.4f}\".format(batch_test_loss))\n",
        "\n",
        "    # 損失をリスト化して保存\n",
        "    train_loss_list.append(batch_train_loss)\n",
        "    test_loss_list.append(batch_test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxK0LeRG8KSS",
        "outputId": "09a0ff17-edb0-410a-bb67-adec7c3c1ca5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------\n",
            "Epoch: 1/100\n",
            "Train_Loss: 28835.7495\n",
            "Test_Loss: 29291.8639\n",
            "--------\n",
            "Epoch: 2/100\n",
            "Train_Loss: 28662.1103\n",
            "Test_Loss: 28882.9371\n",
            "--------\n",
            "Epoch: 3/100\n",
            "Train_Loss: 28002.1978\n",
            "Test_Loss: 28140.5881\n",
            "--------\n",
            "Epoch: 4/100\n",
            "Train_Loss: 27111.3774\n",
            "Test_Loss: 27058.8434\n",
            "--------\n",
            "Epoch: 5/100\n",
            "Train_Loss: 25937.1342\n",
            "Test_Loss: 25694.0805\n",
            "--------\n",
            "Epoch: 6/100\n",
            "Train_Loss: 24398.0963\n",
            "Test_Loss: 24091.6056\n",
            "--------\n",
            "Epoch: 7/100\n",
            "Train_Loss: 22927.1522\n",
            "Test_Loss: 22313.3902\n",
            "--------\n",
            "Epoch: 8/100\n",
            "Train_Loss: 20866.5847\n",
            "Test_Loss: 20410.4621\n",
            "--------\n",
            "Epoch: 9/100\n",
            "Train_Loss: 19009.0562\n",
            "Test_Loss: 18503.0079\n",
            "--------\n",
            "Epoch: 10/100\n",
            "Train_Loss: 17130.0656\n",
            "Test_Loss: 16618.2228\n",
            "--------\n",
            "Epoch: 11/100\n",
            "Train_Loss: 15194.3707\n",
            "Test_Loss: 14780.9455\n",
            "--------\n",
            "Epoch: 12/100\n",
            "Train_Loss: 13420.5298\n",
            "Test_Loss: 13043.0311\n",
            "--------\n",
            "Epoch: 13/100\n",
            "Train_Loss: 11886.9439\n",
            "Test_Loss: 11488.2336\n",
            "--------\n",
            "Epoch: 14/100\n",
            "Train_Loss: 10344.0385\n",
            "Test_Loss: 10077.1257\n",
            "--------\n",
            "Epoch: 15/100\n",
            "Train_Loss: 9053.9670\n",
            "Test_Loss: 8907.1228\n",
            "--------\n",
            "Epoch: 16/100\n",
            "Train_Loss: 7981.4273\n",
            "Test_Loss: 7911.2750\n",
            "--------\n",
            "Epoch: 17/100\n",
            "Train_Loss: 7155.6781\n",
            "Test_Loss: 7109.9349\n",
            "--------\n",
            "Epoch: 18/100\n",
            "Train_Loss: 6417.2816\n",
            "Test_Loss: 6463.5331\n",
            "--------\n",
            "Epoch: 19/100\n",
            "Train_Loss: 5798.5980\n",
            "Test_Loss: 5952.9377\n",
            "--------\n",
            "Epoch: 20/100\n",
            "Train_Loss: 5399.3232\n",
            "Test_Loss: 5583.9745\n",
            "--------\n",
            "Epoch: 21/100\n",
            "Train_Loss: 5039.7692\n",
            "Test_Loss: 5292.4676\n",
            "--------\n",
            "Epoch: 22/100\n",
            "Train_Loss: 4797.2046\n",
            "Test_Loss: 5091.5005\n",
            "--------\n",
            "Epoch: 23/100\n",
            "Train_Loss: 4651.4824\n",
            "Test_Loss: 4934.2978\n",
            "--------\n",
            "Epoch: 24/100\n",
            "Train_Loss: 4480.6911\n",
            "Test_Loss: 4808.7984\n",
            "--------\n",
            "Epoch: 25/100\n",
            "Train_Loss: 4400.3523\n",
            "Test_Loss: 4714.3019\n",
            "--------\n",
            "Epoch: 26/100\n",
            "Train_Loss: 4301.2964\n",
            "Test_Loss: 4633.6553\n",
            "--------\n",
            "Epoch: 27/100\n",
            "Train_Loss: 4244.8972\n",
            "Test_Loss: 4577.0514\n",
            "--------\n",
            "Epoch: 28/100\n",
            "Train_Loss: 4200.9118\n",
            "Test_Loss: 4518.9321\n",
            "--------\n",
            "Epoch: 29/100\n",
            "Train_Loss: 4148.0346\n",
            "Test_Loss: 4466.7538\n",
            "--------\n",
            "Epoch: 30/100\n",
            "Train_Loss: 4109.4221\n",
            "Test_Loss: 4418.7775\n",
            "--------\n",
            "Epoch: 31/100\n",
            "Train_Loss: 4081.8597\n",
            "Test_Loss: 4373.2543\n",
            "--------\n",
            "Epoch: 32/100\n",
            "Train_Loss: 4044.9129\n",
            "Test_Loss: 4328.8995\n",
            "--------\n",
            "Epoch: 33/100\n",
            "Train_Loss: 3990.5865\n",
            "Test_Loss: 4285.2399\n",
            "--------\n",
            "Epoch: 34/100\n",
            "Train_Loss: 3979.5278\n",
            "Test_Loss: 4243.7119\n",
            "--------\n",
            "Epoch: 35/100\n",
            "Train_Loss: 3937.8573\n",
            "Test_Loss: 4203.6430\n",
            "--------\n",
            "Epoch: 36/100\n",
            "Train_Loss: 3916.2534\n",
            "Test_Loss: 4164.1951\n",
            "--------\n",
            "Epoch: 37/100\n",
            "Train_Loss: 3893.6467\n",
            "Test_Loss: 4127.6447\n",
            "--------\n",
            "Epoch: 38/100\n",
            "Train_Loss: 3851.2464\n",
            "Test_Loss: 4086.4242\n",
            "--------\n",
            "Epoch: 39/100\n",
            "Train_Loss: 3847.0716\n",
            "Test_Loss: 4053.8904\n",
            "--------\n",
            "Epoch: 40/100\n",
            "Train_Loss: 3791.6406\n",
            "Test_Loss: 4017.0143\n",
            "--------\n",
            "Epoch: 41/100\n",
            "Train_Loss: 3771.5948\n",
            "Test_Loss: 3983.9643\n",
            "--------\n",
            "Epoch: 42/100\n",
            "Train_Loss: 3794.0886\n",
            "Test_Loss: 3950.6649\n",
            "--------\n",
            "Epoch: 43/100\n",
            "Train_Loss: 3730.2239\n",
            "Test_Loss: 3919.1609\n",
            "--------\n",
            "Epoch: 44/100\n",
            "Train_Loss: 3711.8107\n",
            "Test_Loss: 3885.1373\n",
            "--------\n",
            "Epoch: 45/100\n",
            "Train_Loss: 3688.1714\n",
            "Test_Loss: 3856.8941\n",
            "--------\n",
            "Epoch: 46/100\n",
            "Train_Loss: 3667.3945\n",
            "Test_Loss: 3827.1984\n",
            "--------\n",
            "Epoch: 47/100\n",
            "Train_Loss: 3648.3773\n",
            "Test_Loss: 3797.7838\n",
            "--------\n",
            "Epoch: 48/100\n",
            "Train_Loss: 3649.8969\n",
            "Test_Loss: 3767.9675\n",
            "--------\n",
            "Epoch: 49/100\n",
            "Train_Loss: 3619.0060\n",
            "Test_Loss: 3745.0574\n",
            "--------\n",
            "Epoch: 50/100\n",
            "Train_Loss: 3588.1337\n",
            "Test_Loss: 3715.5749\n",
            "--------\n",
            "Epoch: 51/100\n",
            "Train_Loss: 3590.4906\n",
            "Test_Loss: 3691.9089\n",
            "--------\n",
            "Epoch: 52/100\n",
            "Train_Loss: 3596.0041\n",
            "Test_Loss: 3664.3382\n",
            "--------\n",
            "Epoch: 53/100\n",
            "Train_Loss: 3538.5318\n",
            "Test_Loss: 3638.3927\n",
            "--------\n",
            "Epoch: 54/100\n",
            "Train_Loss: 3543.1834\n",
            "Test_Loss: 3617.9880\n",
            "--------\n",
            "Epoch: 55/100\n",
            "Train_Loss: 3523.2913\n",
            "Test_Loss: 3593.7614\n",
            "--------\n",
            "Epoch: 56/100\n",
            "Train_Loss: 3488.9390\n",
            "Test_Loss: 3566.9023\n",
            "--------\n",
            "Epoch: 57/100\n",
            "Train_Loss: 3488.4783\n",
            "Test_Loss: 3548.6526\n",
            "--------\n",
            "Epoch: 58/100\n",
            "Train_Loss: 3478.3048\n",
            "Test_Loss: 3525.0100\n",
            "--------\n",
            "Epoch: 59/100\n",
            "Train_Loss: 3478.5246\n",
            "Test_Loss: 3505.2547\n",
            "--------\n",
            "Epoch: 60/100\n",
            "Train_Loss: 3444.6924\n",
            "Test_Loss: 3486.5824\n",
            "--------\n",
            "Epoch: 61/100\n",
            "Train_Loss: 3433.0281\n",
            "Test_Loss: 3462.6045\n",
            "--------\n",
            "Epoch: 62/100\n",
            "Train_Loss: 3412.7810\n",
            "Test_Loss: 3443.4554\n",
            "--------\n",
            "Epoch: 63/100\n",
            "Train_Loss: 3410.4221\n",
            "Test_Loss: 3424.4283\n",
            "--------\n",
            "Epoch: 64/100\n",
            "Train_Loss: 3412.1219\n",
            "Test_Loss: 3407.8516\n",
            "--------\n",
            "Epoch: 65/100\n",
            "Train_Loss: 3414.0535\n",
            "Test_Loss: 3389.3556\n",
            "--------\n",
            "Epoch: 66/100\n",
            "Train_Loss: 3366.9450\n",
            "Test_Loss: 3369.4906\n",
            "--------\n",
            "Epoch: 67/100\n",
            "Train_Loss: 3370.9878\n",
            "Test_Loss: 3353.5771\n",
            "--------\n",
            "Epoch: 68/100\n",
            "Train_Loss: 3348.2160\n",
            "Test_Loss: 3334.4933\n",
            "--------\n",
            "Epoch: 69/100\n",
            "Train_Loss: 3359.5022\n",
            "Test_Loss: 3321.1067\n",
            "--------\n",
            "Epoch: 70/100\n",
            "Train_Loss: 3320.5591\n",
            "Test_Loss: 3301.3463\n",
            "--------\n",
            "Epoch: 71/100\n",
            "Train_Loss: 3321.7287\n",
            "Test_Loss: 3288.7820\n",
            "--------\n",
            "Epoch: 72/100\n",
            "Train_Loss: 3318.1490\n",
            "Test_Loss: 3273.0576\n",
            "--------\n",
            "Epoch: 73/100\n",
            "Train_Loss: 3316.1360\n",
            "Test_Loss: 3258.8591\n",
            "--------\n",
            "Epoch: 74/100\n",
            "Train_Loss: 3290.3406\n",
            "Test_Loss: 3242.7606\n",
            "--------\n",
            "Epoch: 75/100\n",
            "Train_Loss: 3280.3013\n",
            "Test_Loss: 3229.9910\n",
            "--------\n",
            "Epoch: 76/100\n",
            "Train_Loss: 3271.1087\n",
            "Test_Loss: 3217.0840\n",
            "--------\n",
            "Epoch: 77/100\n",
            "Train_Loss: 3277.3122\n",
            "Test_Loss: 3200.4997\n",
            "--------\n",
            "Epoch: 78/100\n",
            "Train_Loss: 3306.5792\n",
            "Test_Loss: 3191.5533\n",
            "--------\n",
            "Epoch: 79/100\n",
            "Train_Loss: 3243.2753\n",
            "Test_Loss: 3175.9180\n",
            "--------\n",
            "Epoch: 80/100\n",
            "Train_Loss: 3234.5735\n",
            "Test_Loss: 3167.2496\n",
            "--------\n",
            "Epoch: 81/100\n",
            "Train_Loss: 3242.5399\n",
            "Test_Loss: 3152.2235\n",
            "--------\n",
            "Epoch: 82/100\n",
            "Train_Loss: 3253.1690\n",
            "Test_Loss: 3142.4638\n",
            "--------\n",
            "Epoch: 83/100\n",
            "Train_Loss: 3223.1185\n",
            "Test_Loss: 3127.3178\n",
            "--------\n",
            "Epoch: 84/100\n",
            "Train_Loss: 3213.3724\n",
            "Test_Loss: 3117.6700\n",
            "--------\n",
            "Epoch: 85/100\n",
            "Train_Loss: 3204.6090\n",
            "Test_Loss: 3106.8110\n",
            "--------\n",
            "Epoch: 86/100\n",
            "Train_Loss: 3222.1569\n",
            "Test_Loss: 3092.8447\n",
            "--------\n",
            "Epoch: 87/100\n",
            "Train_Loss: 3207.9822\n",
            "Test_Loss: 3083.3015\n",
            "--------\n",
            "Epoch: 88/100\n",
            "Train_Loss: 3188.1364\n",
            "Test_Loss: 3075.2874\n",
            "--------\n",
            "Epoch: 89/100\n",
            "Train_Loss: 3185.7586\n",
            "Test_Loss: 3064.6221\n",
            "--------\n",
            "Epoch: 90/100\n",
            "Train_Loss: 3167.1723\n",
            "Test_Loss: 3051.8469\n",
            "--------\n",
            "Epoch: 91/100\n",
            "Train_Loss: 3167.7206\n",
            "Test_Loss: 3044.1847\n",
            "--------\n",
            "Epoch: 92/100\n",
            "Train_Loss: 3183.5478\n",
            "Test_Loss: 3036.2042\n",
            "--------\n",
            "Epoch: 93/100\n",
            "Train_Loss: 3160.8693\n",
            "Test_Loss: 3024.3418\n",
            "--------\n",
            "Epoch: 94/100\n",
            "Train_Loss: 3175.6515\n",
            "Test_Loss: 3014.0407\n",
            "--------\n",
            "Epoch: 95/100\n",
            "Train_Loss: 3138.8287\n",
            "Test_Loss: 3009.6629\n",
            "--------\n",
            "Epoch: 96/100\n",
            "Train_Loss: 3136.0405\n",
            "Test_Loss: 3001.7007\n",
            "--------\n",
            "Epoch: 97/100\n",
            "Train_Loss: 3159.9215\n",
            "Test_Loss: 2991.9380\n",
            "--------\n",
            "Epoch: 98/100\n",
            "Train_Loss: 3127.7101\n",
            "Test_Loss: 2981.1659\n",
            "--------\n",
            "Epoch: 99/100\n",
            "Train_Loss: 3131.6753\n",
            "Test_Loss: 2981.1660\n",
            "--------\n",
            "Epoch: 100/100\n",
            "Train_Loss: 3171.4670\n",
            "Test_Loss: 2967.1556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.title('Train and Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(range(1, epoch + 1), train_loss_list, color='blue', linestyle='-', label='Train_Loss')\n",
        "plt.plot(range(1, epoch + 1), test_loss_list, color='red', linestyle='--', label='Test_Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JYs0Hio_8MjZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
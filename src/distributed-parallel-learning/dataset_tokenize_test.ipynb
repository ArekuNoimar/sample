{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2-4fmBm3eEUu",
        "outputId": "091130b4-59ff-4618-f4be-60020d408389"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install 'transformers==4.51.3'\n",
        "!pip install 'numpy==2.1.2'\n",
        "!pip install 'datasets==3.5.0'\n",
        "!pip install 'huggingface_hub[cli]==0.30.2'\n",
        "!pip install 'deepspeed==0.16.7' --use-pep517\n",
        "!pip install 'accelerate==1.6.0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wV_2TXekf5tX"
      },
      "outputs": [],
      "source": [
        "# Set Environment Variables\n",
        "default_environment_variables = {\n",
        "    \"output_dir\": \"./training_output\",\n",
        "    \"wandb_account_name\": \"arekunoimar-deepspeed\",\n",
        "    \"wandb_project_name\": \"llama-3-2-1b\",\n",
        "    \"model_name\": \"meta-llama/Llama-3.2-1B\",\n",
        "    \"dataset\": \"alpaca_data.json\",\n",
        "    \"dataset_max_length\": 512,\n",
        "    \"apply_dataset_rate\": 0.1,\n",
        "    \"dataset_train_rate\": 0.8,\n",
        "    \"dataset_validation_rate\": 0.1,\n",
        "    \"num_train_epochs\": 1,\n",
        "    \"per_device_train_batch_size\": 1,\n",
        "    \"per_device_eval_batch_size\": 1,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"max_grad_norm\": 1.0,\n",
        "    \"optim\": \"adamw_torch\",\n",
        "    \"logging_steps\": 1,\n",
        "    \"learning_rate\": 2e-5,\n",
        "    \"lr_scheduler_type\": \"cosine\",\n",
        "    \"warmup_steps\": 700,\n",
        "    \"seed\": 1024,\n",
        "    \"fp16\": False,\n",
        "    \"bf16\": True,\n",
        "    \"save_strategy\": \"steps\",\n",
        "    \"save_steps\": 1000,\n",
        "    \"save_total_limit\": 1,\n",
        "    \"eval_strategy\": \"steps\",\n",
        "    \"eval_steps\": 1000,\n",
        "    \"do_eval\": True,\n",
        "    \"logging_distance_time\": 1,\n",
        "    # \"deepspeed_zero0\": False,\n",
        "    # \"deepspeed_train_config_zero0_path\":\"deepspeed_train_config_zero0.json\",\n",
        "    # \"deepspeed_zero1\": False,\n",
        "    # \"deepspeed_train_config_zero1_path\":\"deepspeed_train_config_zero1.json\",\n",
        "    # \"deepspeed_zero2\": True,\n",
        "    # \"deepspeed_train_config_zero2_path\":\"deepspeed_train_config_zero2.json\",\n",
        "    # \"deepspeed_zero3\": False,\n",
        "    # \"deepspeed_train_config_zero3_path\":\"deepspeed_train_config_zero3.json\",\n",
        "    # \"deepspeed_zero3_infinity\": False,\n",
        "    # \"deepspeed_train_config_zero3_infinity_path\":\"deepspeed_train_config_zero3_infinity.json\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "deepspeed_zero2_config = {\n",
        "  \"zero_optimization\": {\n",
        "    \"stage\": 2\n",
        "  },\n",
        "  \"train_batch_size\": 1,\n",
        "  \"eval_batch_size\": 1\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTKta3TfgWti"
      },
      "outputs": [],
      "source": [
        "# download model\n",
        "from huggingface_hub import snapshot_download, login\n",
        "# login()\n",
        "snapshot_download(repo_id=default_environment_variables[\"model_name\"], local_dir_use_symlinks=False, revision=\"main\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DT56bUbSgALw"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-yY9gzgfGPT"
      },
      "outputs": [],
      "source": [
        "# load model, tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(default_environment_variables[\"model_name\"])\n",
        "model = AutoModelForCausalLM.from_pretrained(default_environment_variables[\"model_name\"])\n",
        "\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "h2TFosyUmOkG"
      },
      "outputs": [],
      "source": [
        "# read dataset\n",
        "import pandas\n",
        "import json\n",
        "\n",
        "def load_alpaca_dataset():\n",
        "  with open(default_environment_variables[\"dataset\"], 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "  dataframe = pandas.DataFrame(data)\n",
        "  dataframe = dataframe[['instruction', 'input', 'output']]\n",
        "  dataframe.head(100)\n",
        "  return dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTzHrRXarBof"
      },
      "outputs": [],
      "source": [
        "dataframe = load_alpaca_dataset()\n",
        "print(dataframe.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DClBMJJqu2Mi"
      },
      "outputs": [],
      "source": [
        "# apply dataformat\n",
        "\n",
        "def apply_dataset_dataformat(dataframe):\n",
        "  formated_dataframe = dataframe.apply(lambda x: {'###instruction': x['instruction'], '###input': x['input'], '###output': x['output']}, axis=1)\n",
        "  return formated_dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwiG0asdwHw7"
      },
      "outputs": [],
      "source": [
        "formated_dataframe = apply_dataset_dataformat(dataframe)\n",
        "print(formated_dataframe.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "rSRZWox1oiUk"
      },
      "outputs": [],
      "source": [
        "# split dataset\n",
        "\n",
        "def split_alpaca_dataset(dataframe):\n",
        "  total_size_dataset = dataframe.sample(frac=default_environment_variables[\"apply_dataset_rate\"])\n",
        "  total_size_count = len(total_size_dataset)\n",
        "\n",
        "  train_size = int(len(total_size_dataset) * default_environment_variables[\"dataset_train_rate\"])\n",
        "  validation_size = int(len(total_size_dataset) * default_environment_variables[\"dataset_validation_rate\"])\n",
        "  test_size = total_size_count - (train_size + validation_size)\n",
        "\n",
        "  train_dataset = total_size_dataset.iloc[:train_size]\n",
        "  validation_dataset = total_size_dataset.iloc[train_size:train_size + validation_size]\n",
        "  test_dataset = total_size_dataset.iloc[train_size + validation_size:]\n",
        "\n",
        "  return train_dataset, validation_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVHCw-yVt-o8"
      },
      "outputs": [],
      "source": [
        "train_dataset, validation_dataset, test_dataset = split_alpaca_dataset(load_alpaca_dataset())\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(validation_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "7LTURCm04evv"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9LcZwQh4WKj"
      },
      "outputs": [],
      "source": [
        "# check befor model output\n",
        "test_qa_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_length=100, eos_token_id=tokenizer.eos_token_id, pad_token_id=tokenizer.pad_token_id)\n",
        "prompt = \"###instruction: Please answer the questions.  ###input: what is AI ?  ### output:\"\n",
        "generate_text = test_qa_pipeline(prompt, max_length=100, num_return_sequences=1, temperature=0.8)[0][\"generated_text\"]\n",
        "print(generate_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjjSVqN_3GFe"
      },
      "outputs": [],
      "source": [
        "# set training_args\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=default_environment_variables[\"output_dir\"],\n",
        "    num_train_epochs=default_environment_variables[\"num_train_epochs\"],\n",
        "    per_device_train_batch_size=default_environment_variables[\"per_device_train_batch_size\"],\n",
        "    per_device_eval_batch_size=default_environment_variables[\"per_device_eval_batch_size\"],\n",
        "    gradient_accumulation_steps=default_environment_variables[\"gradient_accumulation_steps\"],\n",
        "    max_grad_norm=default_environment_variables[\"max_grad_norm\"],\n",
        "    optim=default_environment_variables[\"optim\"],\n",
        "    learning_rate=default_environment_variables[\"learning_rate\"],\n",
        "    weight_decay=default_environment_variables[\"weight_decay\"],\n",
        "    lr_scheduler_type=default_environment_variables[\"lr_scheduler_type\"],\n",
        "    warmup_steps=default_environment_variables[\"warmup_steps\"],\n",
        "    logging_steps=default_environment_variables[\"logging_steps\"],\n",
        "    seed=default_environment_variables[\"seed\"],\n",
        "    fp16=default_environment_variables[\"fp16\"],\n",
        "    bf16=default_environment_variables[\"bf16\"],\n",
        "    deepspeed=deepspeed_zero2_config,\n",
        "    save_strategy=default_environment_variables[\"save_strategy\"],\n",
        "    save_steps=default_environment_variables[\"save_steps\"],\n",
        "    save_total_limit=default_environment_variables[\"save_total_limit\"],\n",
        "    eval_strategy=default_environment_variables[\"eval_strategy\"],\n",
        "    eval_steps=default_environment_variables[\"eval_steps\"],\n",
        "    do_eval=default_environment_variables[\"do_eval\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data_collator\n",
        "def data_collator(tokenizer):\n",
        "  data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False, pad_to_multiple_of=8)\n",
        "  return data_collator"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "password = input(\"Enter the password: \")\n",
        "!echo {password} | sudo -S apt-get install mpich -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set env\n",
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "os.environ[\"RANK\"] = \"0\"\n",
        "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
        "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
        "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
        "os.environ[\"MASTER_PORT\"] = \"29500\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2-4fmBm3eEUu",
        "outputId": "091130b4-59ff-4618-f4be-60020d408389"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install 'transformers==4.51.3'\n",
        "!pip install 'numpy==1.26.4'\n",
        "!pip install 'datasets==3.5.0'\n",
        "!pip install 'huggingface_hub[cli]==0.30.2'\n",
        "!pip install 'deepspeed==0.16.7' --use-pep517\n",
        "!pip install 'trl==0.19.0'\n",
        "!pip install 'mpi4py'\n",
        "!pip install 'wandb==0.19.10'\n",
        "!pip install 'peft==0.15.2'\n",
        "!pip install ipykernel jupyter_client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wV_2TXekf5tX"
      },
      "outputs": [],
      "source": [
        "# Set Environment Variables\n",
        "default_environment_variables = {\n",
        "    \"output_dir\": \"./output/llama-3-2-1b-alpaca\",\n",
        "    \"wandb_account_name\": \"arekunoimar-deepspeed\",\n",
        "    \"wandb_project_name\": \"llama-3-2-1b\",\n",
        "    \"model_name\": \"meta-llama/Llama-3.2-1B\",\n",
        "    \"dataset\": \"../dataset/alpaca_data.json\",\n",
        "    \"dataset_max_length\": 512,\n",
        "    \"apply_dataset_rate\": 1.0,\n",
        "    \"dataset_train_rate\": 0.8,\n",
        "    \"dataset_validation_rate\": 0.2,\n",
        "    \"num_train_epochs\": 3,\n",
        "    \"per_device_train_batch_size\": 1,\n",
        "    \"per_device_eval_batch_size\": 1,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"max_grad_norm\": 1.0,\n",
        "    \"optim\": \"adamw_torch\",\n",
        "    \"logging_steps\": 1,\n",
        "    \"learning_rate\": 2e-5,\n",
        "    \"lr_scheduler_type\": \"cosine\",\n",
        "    \"warmup_ratio\": 0.05,\n",
        "    \"seed\": 1024,\n",
        "    \"fp16\": False,\n",
        "    \"bf16\": True,\n",
        "    \"save_strategy\": \"steps\",\n",
        "    \"save_steps\": 10000,\n",
        "    \"save_total_limit\": 5,\n",
        "    \"eval_strategy\": \"steps\",\n",
        "    \"eval_steps\": 10000,\n",
        "    \"do_eval\": True,\n",
        "    \"logging_distance_time\": 1,\n",
        "    \"weight_decay\": 0.001,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "import time\n",
        "\n",
        "wandb_name = \"llama-3.2-1b-alpaca-deepspeed-zero2-\" + time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "wandb.init(project=default_environment_variables[\"wandb_project_name\"], entity=default_environment_variables[\"wandb_account_name\"], name=wandb_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set deepspeed config\n",
        "deepspeed_zero2_config = {\n",
        "  \"zero_optimization\": {\n",
        "    \"stage\": 2\n",
        "  },\n",
        "  \"train_batch_size\": 1,\n",
        "  \"eval_batch_size\": 1\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "# マトリックス乗算で TF32 を許可\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "# cuDNN（畳み込み等）で TF32 を許可\n",
        "torch.backends.cudnn.allow_tf32 = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-yY9gzgfGPT"
      },
      "outputs": [],
      "source": [
        "# load model, tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(default_environment_variables[\"model_name\"])\n",
        "model = AutoModelForCausalLM.from_pretrained(default_environment_variables[\"model_name\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set tokenizer special token\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "h2TFosyUmOkG"
      },
      "outputs": [],
      "source": [
        "# read dataset\n",
        "import pandas\n",
        "import json\n",
        "\n",
        "def load_alpaca_dataset():\n",
        "  with open(default_environment_variables[\"dataset\"], 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "  dataframe = pandas.DataFrame(data)\n",
        "  dataframe = dataframe[['instruction', 'input', 'output']]\n",
        "  dataframe.head(100)\n",
        "  return dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTzHrRXarBof"
      },
      "outputs": [],
      "source": [
        "dataframe = load_alpaca_dataset()\n",
        "print(dataframe.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DClBMJJqu2Mi"
      },
      "outputs": [],
      "source": [
        "# apply dataformat\n",
        "def apply_dataset_dataformat(dataframe):\n",
        "    def format_instruction(row):\n",
        "        if row['input']:\n",
        "            text = f\"###instruction:\\n{row['instruction']}\\n###input:\\n{row['input']}\\n###output:\\n{row['output']}\"\n",
        "        else:\n",
        "            text = f\"###instruction:\\n{row['instruction']}\\n###output:\\n{row['output']}\"\n",
        "        return text\n",
        "    \n",
        "    formated_dataframe = dataframe.apply(format_instruction, axis=1)\n",
        "    return formated_dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwiG0asdwHw7"
      },
      "outputs": [],
      "source": [
        "formated_dataframe = apply_dataset_dataformat(dataframe)\n",
        "print(formated_dataframe.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rSRZWox1oiUk"
      },
      "outputs": [],
      "source": [
        "# split dataset\n",
        "def split_alpaca_dataset(dataframe):\n",
        "  total_size_dataset = dataframe.sample(frac=default_environment_variables[\"apply_dataset_rate\"])\n",
        "  total_size_count = len(total_size_dataset)\n",
        "\n",
        "  train_size = int(len(total_size_dataset) * default_environment_variables[\"dataset_train_rate\"])\n",
        "  validation_size = int(len(total_size_dataset) * default_environment_variables[\"dataset_validation_rate\"])\n",
        "  test_size = total_size_count - (train_size + validation_size)\n",
        "\n",
        "  train_dataset = total_size_dataset.iloc[:train_size]\n",
        "  validation_dataset = total_size_dataset.iloc[train_size:train_size + validation_size]\n",
        "  test_dataset = total_size_dataset.iloc[train_size + validation_size:]\n",
        "\n",
        "  return train_dataset, validation_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVHCw-yVt-o8"
      },
      "outputs": [],
      "source": [
        "train_dataset, validation_dataset, test_dataset = split_alpaca_dataset(load_alpaca_dataset())\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(validation_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7LTURCm04evv"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9LcZwQh4WKj"
      },
      "outputs": [],
      "source": [
        "# check befor model output\n",
        "test_qa_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_length=100, eos_token_id=tokenizer.eos_token_id, pad_token_id=tokenizer.pad_token_id)\n",
        "prompt = \"\"\"\n",
        "###instruction:\\nPlease answer the questions.\\n###input:\\nWhat is AI?\\n###output:\n",
        "\"\"\"\n",
        "generate_text = test_qa_pipeline(prompt, max_length=512, num_return_sequences=1, temperature=0.8)[0][\"generated_text\"]\n",
        "print(generate_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from trl import DataCollatorForCompletionOnlyLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DataCollator setting\n",
        "collator = DataCollatorForCompletionOnlyLM(response_template=\"###output:\\n\", tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjjSVqN_3GFe"
      },
      "outputs": [],
      "source": [
        "# set training_args\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=default_environment_variables[\"output_dir\"],\n",
        "    num_train_epochs=default_environment_variables[\"num_train_epochs\"],\n",
        "    per_device_train_batch_size=default_environment_variables[\"per_device_train_batch_size\"],\n",
        "    per_device_eval_batch_size=default_environment_variables[\"per_device_eval_batch_size\"],\n",
        "    gradient_accumulation_steps=default_environment_variables[\"gradient_accumulation_steps\"],\n",
        "    max_grad_norm=default_environment_variables[\"max_grad_norm\"],\n",
        "    optim=default_environment_variables[\"optim\"],\n",
        "    learning_rate=default_environment_variables[\"learning_rate\"],\n",
        "    weight_decay=default_environment_variables[\"weight_decay\"],\n",
        "    lr_scheduler_type=default_environment_variables[\"lr_scheduler_type\"],\n",
        "    warmup_ratio=default_environment_variables[\"warmup_ratio\"],\n",
        "    logging_steps=default_environment_variables[\"logging_steps\"],\n",
        "    seed=default_environment_variables[\"seed\"],\n",
        "    fp16=default_environment_variables[\"fp16\"],\n",
        "    bf16=default_environment_variables[\"bf16\"],\n",
        "    deepspeed=deepspeed_zero2_config,\n",
        "    save_strategy=default_environment_variables[\"save_strategy\"],\n",
        "    save_steps=default_environment_variables[\"save_steps\"],\n",
        "    save_total_limit=default_environment_variables[\"save_total_limit\"],\n",
        "    eval_strategy=default_environment_variables[\"eval_strategy\"],\n",
        "    eval_steps=default_environment_variables[\"eval_steps\"],\n",
        "    do_eval=default_environment_variables[\"do_eval\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# format dataset\n",
        "train_formatted = apply_dataset_dataformat(train_dataset)\n",
        "print(f\"train_formatted: {train_formatted}\")\n",
        "validation_formatted = apply_dataset_dataformat(validation_dataset)\n",
        "print(f\"validation_formatted: {validation_formatted}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check dataset values\n",
        "train_hf_dataset = Dataset.from_dict({\"text\": train_formatted.tolist()})\n",
        "validation_hf_dataset = Dataset.from_dict({\"text\": validation_formatted.tolist()})\n",
        "print(f\"train_hf_dataset: {train_hf_dataset}\")\n",
        "print(f\"validation_hf_dataset: {validation_hf_dataset}\")\n",
        "\n",
        "print('-'*10 + 'train_hf_dataset' + '-'*10)\n",
        "for i in range(10):\n",
        "    print(train_hf_dataset[i]['text'])\n",
        "print('-'*10 + 'validation_hf_dataset' + '-'*10)\n",
        "for i in range(10):\n",
        "    print(validation_hf_dataset[i]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SFTTrainer setting\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_hf_dataset,\n",
        "    eval_dataset=validation_hf_dataset,\n",
        "    args=training_arguments,\n",
        "    data_collator=collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save_model() # save model\n",
        "trainer.save_state() # save metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ipykernel\n",
        "from jupyter_client import KernelManager\n",
        "import os\n",
        "\n",
        "def stop_kernel():\n",
        "    try:\n",
        "        # 現在のカーネルIDを取得\n",
        "        connection_file = ipykernel.get_connection_file()\n",
        "        kernel_id = os.path.basename(connection_file).replace('kernel-', '').replace('.json', '')\n",
        "        \n",
        "        # カーネルマネージャーを使用してカーネルを停止\n",
        "        km = KernelManager(kernel_name='python3')\n",
        "        km.kernel_spec = kernel_id\n",
        "        km.shutdown_kernel()\n",
        "        print(\"カーネルを正常に停止しました。\")\n",
        "    except Exception as e:\n",
        "        print(f\"カーネル停止エラー: {e}\")\n",
        "\n",
        "print(\"プログラム開始\")\n",
        "# ここに処理を記述\n",
        "stop_kernel()\n",
        "print(\"プログラム終了\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
